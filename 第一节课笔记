从千禧年到2021年，主要以专用模型作为机器学习的主要训练模式
2023年6月发布了首个千亿大模型，并在后续不断迭代更新
在2024年1月7日，InternLM 2正式开源


在InternLM 2模型中，多个项目领先于Chat gpt3.5甚至接近于Chatgpt4.0，模型在综合性能方面属于开源模型中的领先水平
在对话方面，InternLM2模型输出的内容条理清晰，层次分明，询问情感相关问题时或充满人文关怀

XTuner
由上海人工智能实验室推出的大模型训练，微调工具箱，可选择全局或部分参数微调
仅需8G显存即可运行7Blite模型，仅需24G显存即可使用20B综合模型
模型在中文场景具有性能优势
